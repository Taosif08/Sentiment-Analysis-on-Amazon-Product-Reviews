{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4651dd8e",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Amazon Product Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaf52db",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview\n",
    "- **Dataset Description**:\n",
    "  - Analyze an Amazon product review dataset containing textual reviews (`reviewText`) and corresponding sentiment labels (`Positive`).\n",
    "  - Sentiment is binary: 1 for positive, 0 for negative.\n",
    "- **Objective**:\n",
    "  - Predict the sentiment of a product review based on its textual content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aec67bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\afifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\afifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\afifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\afifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('punkt')  # Tokenizer\n",
    "nltk.download('wordnet')  # Lemmatizer\n",
    "nltk.download('stopwords')  # Stopwords\n",
    "nltk.download('omw-1.4')  # WordNet extensions for lemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "234f8c9e-a2d4-42e4-8bb7-3f95bac99e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92730c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a one of the best apps acording to a b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a pretty good version of the game for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a really cool game. there are a bunch ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a silly game and can be frustrating, b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a terrific game on any pad. Hrs of fun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  Positive\n",
       "0  This is a one of the best apps acording to a b...         1\n",
       "1  This is a pretty good version of the game for ...         1\n",
       "2  this is a really cool game. there are a bunch ...         1\n",
       "3  This is a silly game and can be frustrating, b...         1\n",
       "4  This is a terrific game on any pad. Hrs of fun...         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/rashakil-ds/Public-Datasets/refs/heads/main/amazon.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da27b7a2",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "- Handle missing values, if any.\n",
    "- Perform text preprocessing on the `reviewText` column:\n",
    "  - Convert text to lowercase.\n",
    "  - Remove stop words, punctuation, and special characters.\n",
    "  - Tokenize and lemmatize text data.\n",
    "- Split the dataset into training and testing sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c497ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['reviewText', 'Positive'])  \n",
    "X = df['reviewText'].astype(str)\n",
    "y = df['Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db5941a2-2301-4c0a-9893-393f43c7ca46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    0\n",
       "Positive      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86e83cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewText'] = df['reviewText'].fillna('')\n",
    "df['Positive'] = df['Positive'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5b6a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a20b110-7365-437f-90ae-5efcc6fa3961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and special characters\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and lemmatize tokens\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    # Join tokens back to a single string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the reviewText column\n",
    "df['reviewText'] = df['reviewText'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75c54d77-8c4d-474e-bed0-630799862af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 2000  \n",
    "max_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23277632-b38b-42b4-9def-f16300d2ff89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one best apps acording bunch people agree bomb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pretty good version game free lot different le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>really cool game bunch level find golden egg s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>silly game frustrating lot fun definitely reco...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terrific game pad hr fun grandkids love great ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  Positive\n",
       "0  one best apps acording bunch people agree bomb...         1\n",
       "1  pretty good version game free lot different le...         1\n",
       "2  really cool game bunch level find golden egg s...         1\n",
       "3  silly game frustrating lot fun definitely reco...         1\n",
       "4  terrific game pad hr fun grandkids love great ...         1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "096f430a-c522-4fb1-b182-26ca6feaf854",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<nothing>\")\n",
    "tokenizer.fit_on_texts(df['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8129fbc-0f5b-4e0c-8c64-2889f3c97bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = tokenizer.texts_to_sequences(df['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "103b215a-2e95-487b-8aa9-60d3d4db9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_seq = pad_sequences(seq, max_len, padding='post')\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_seq, df['Positive'], test_size=0.3, random_state=24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec98fa4a",
   "metadata": {},
   "source": [
    "## 3. Model Selection\n",
    "- Choose at least three machine learning models for sentiment classification:\n",
    "  - Statistical Models:\n",
    "    - Logistic Regression\n",
    "    - Random Forest\n",
    "    - Support Vector Machine (SVM)\n",
    "    - Naïve Bayes\n",
    "    - Gradient Boosting (e.g., XGBoost, AdaBoost, CatBoost)\n",
    "  - Neural Models:\n",
    "    - LSTM (Long Short-Term Memory)\n",
    "    - GRUs (Gated Recurrent Units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f250dc92-8296-4471-9ce6-893456e08102",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm = SVC(kernel='linear', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2171b588-0731-4349-b100-019024539cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b6b0a20-590b-405e-aaa7-f5ef2b3241ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(32, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591140e4-d3ff-4c3f-b06e-33cd614439b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d561e8",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "- Train each selected model on the training dataset.\n",
    "- Utilize vectorization techniques for text data:\n",
    "  - TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "  - Word embeddings (e.g., Word2Vec, GloVe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64ac10d0-a5c2-4063-bf72-78cdaf867af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df['reviewText']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88efef53-6baf-41e1-8c22-1c4519a31b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_trainn, y_testt = train_test_split(tfidf_features, df['Positive'], test_size=0.3, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c1edc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8911666666666667, 0.8911666666666667)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(x_train, y_trainn)\n",
    "y_pred_svm = svm.predict(x_test)\n",
    "svm_accuracy = accuracy_score(y_testt, y_pred_svm)\n",
    "svm_score = svm.score(x_test, y_testt)\n",
    "svm_accuracy , svm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a27e749c-bb0f-450a-92dc-46a2309ea89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8488333333333333"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(x_train, y_trainn)\n",
    "y_pred_nb = nb.predict(x_test)\n",
    "nb_accuracy = accuracy_score(y_testt, y_pred_nb)\n",
    "nb_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e28f1c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8675"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train, y_trainn)\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "rf_accuracy = accuracy_score(y_testt, y_pred_rf)\n",
    "\n",
    "rf_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ddd3182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8881666666666667"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train, y_trainn)\n",
    "y_pred_log_reg = log_reg.predict(x_test)\n",
    "log_reg_acc = accuracy_score(y_testt, y_pred_log_reg)\n",
    "#log_reg_score = log_reg.score(x_test, y_testt)\n",
    "log_reg_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1a7f9e9-3cb0-4126-bb9b-8dcc9948f058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - accuracy: 0.7518 - loss: 0.5583 - val_accuracy: 0.7573 - val_loss: 0.5634\n",
      "Epoch 2/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 35ms/step - accuracy: 0.7596 - loss: 0.5535 - val_accuracy: 0.7573 - val_loss: 0.5548\n",
      "Epoch 3/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 35ms/step - accuracy: 0.7607 - loss: 0.5514 - val_accuracy: 0.7573 - val_loss: 0.5546\n",
      "Epoch 4/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 35ms/step - accuracy: 0.7635 - loss: 0.5482 - val_accuracy: 0.7573 - val_loss: 0.5555\n",
      "Epoch 5/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 35ms/step - accuracy: 0.7640 - loss: 0.5474 - val_accuracy: 0.7573 - val_loss: 0.5542\n",
      "Epoch 6/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 37ms/step - accuracy: 0.7653 - loss: 0.5454 - val_accuracy: 0.7573 - val_loss: 0.5554\n",
      "Epoch 7/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.7651 - loss: 0.5457 - val_accuracy: 0.7573 - val_loss: 0.5542\n",
      "Epoch 8/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.7639 - loss: 0.5472 - val_accuracy: 0.7573 - val_loss: 0.5545\n",
      "Epoch 9/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.7593 - loss: 0.5523 - val_accuracy: 0.7573 - val_loss: 0.5543\n",
      "Epoch 10/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.7622 - loss: 0.5488 - val_accuracy: 0.7573 - val_loss: 0.5542\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,        \n",
    "    y_train,         \n",
    "    epochs=10,            \n",
    "    batch_size=32,        \n",
    "    validation_data=(X_test, y_test)  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb787f72-f4e6-451e-9beb-89cdf147ab26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 52ms/step - accuracy: 0.7574 - loss: 0.5508 - val_accuracy: 0.7573 - val_loss: 0.5570\n",
      "Epoch 2/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 55ms/step - accuracy: 0.7639 - loss: 0.5482 - val_accuracy: 0.7573 - val_loss: 0.5546\n",
      "Epoch 3/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 54ms/step - accuracy: 0.7666 - loss: 0.5442 - val_accuracy: 0.7573 - val_loss: 0.5544\n",
      "Epoch 4/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 50ms/step - accuracy: 0.7576 - loss: 0.5543 - val_accuracy: 0.7573 - val_loss: 0.5554\n",
      "Epoch 5/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 54ms/step - accuracy: 0.7704 - loss: 0.5392 - val_accuracy: 0.7573 - val_loss: 0.5541\n",
      "Epoch 6/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 58ms/step - accuracy: 0.7684 - loss: 0.5418 - val_accuracy: 0.7573 - val_loss: 0.5551\n",
      "Epoch 7/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 56ms/step - accuracy: 0.7621 - loss: 0.5492 - val_accuracy: 0.7573 - val_loss: 0.5553\n",
      "Epoch 8/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 56ms/step - accuracy: 0.7657 - loss: 0.5445 - val_accuracy: 0.7573 - val_loss: 0.5544\n",
      "Epoch 9/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 54ms/step - accuracy: 0.7649 - loss: 0.5455 - val_accuracy: 0.7573 - val_loss: 0.5548\n",
      "Epoch 10/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 51ms/step - accuracy: 0.7695 - loss: 0.5403 - val_accuracy: 0.7573 - val_loss: 0.5548\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,        \n",
    "    y_train,         \n",
    "    epochs=10,            \n",
    "    batch_size=32,        \n",
    "    validation_data=(X_test, y_test)  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7b49e8d-48a7-4ec9-bbc2-fc5f94279f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7556 - loss: 0.5564\n"
     ]
    }
   ],
   "source": [
    "lstm_eval=model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7c2621-9747-4018-80be-86ee82e7a992",
   "metadata": {},
   "source": [
    "## 5. Formal Evaluation\n",
    "- Evaluate the performance of each model on the testing set using the following metrics:\n",
    "  - Accuracy\n",
    "  - Precision\n",
    "  - Recall\n",
    "  - F1 Score\n",
    "  - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5d39be4-93d0-4875-81fc-8c4a94ea8129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.8881666666666667\n",
      "Logistic Regression - Precision: 0.8911331044233488\n",
      "Logistic Regression - Recall: 0.9709507042253521\n",
      "Logistic Regression - F1 Score: 0.9293312269615587\n",
      "Logistic Regression - Confusion Matrix:\n",
      " [[ 917  539]\n",
      " [ 132 4412]]\n"
     ]
    }
   ],
   "source": [
    "log_reg_precision = precision_score(y_testt, y_pred_log_reg)\n",
    "log_reg_recall = recall_score(y_testt, y_pred_log_reg)\n",
    "log_reg_f1 = f1_score(y_testt, y_pred_log_reg)\n",
    "log_reg_confusion = confusion_matrix(y_testt, y_pred_log_reg)\n",
    "\n",
    "print(\"Logistic Regression - Accuracy:\", log_reg_acc)\n",
    "print(\"Logistic Regression - Precision:\", log_reg_precision)\n",
    "print(\"Logistic Regression - Recall:\", log_reg_recall)\n",
    "print(\"Logistic Regression - F1 Score:\", log_reg_f1)\n",
    "print(\"Logistic Regression - Confusion Matrix:\\n\", log_reg_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50c72821-e471-4082-8215-920f50d89480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Accuracy: 0.8911666666666667\n",
      "SVM - Precision: 0.9088043706661063\n",
      "SVM - Recall: 0.9518045774647887\n",
      "SVM - F1 Score: 0.9298075889498011\n",
      "SVM - Confusion Matrix:\n",
      " [[1022  434]\n",
      " [ 219 4325]]\n"
     ]
    }
   ],
   "source": [
    "svm_precision = precision_score(y_testt, y_pred_svm)\n",
    "svm_recall = recall_score(y_testt, y_pred_svm)\n",
    "svm_f1 = f1_score(y_testt, y_pred_svm)\n",
    "svm_confusion = confusion_matrix(y_testt, y_pred_svm)\n",
    "print(\"SVM - Accuracy:\", svm_accuracy)\n",
    "print(\"SVM - Precision:\", svm_precision)\n",
    "print(\"SVM - Recall:\", svm_recall)\n",
    "print(\"SVM - F1 Score:\", svm_f1)\n",
    "print(\"SVM - Confusion Matrix:\\n\", svm_confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6b8afc4-efa6-44c0-b746-f47acfb5da66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.8675\n",
      "Random Forest - Precision: 0.8709677419354839\n",
      "Random Forest - Recall: 0.9685299295774648\n",
      "Random Forest - F1 Score: 0.9171616130040637\n",
      "Random Forest - Confusion Matrix:\n",
      " [[ 804  652]\n",
      " [ 143 4401]]\n"
     ]
    }
   ],
   "source": [
    "rf_precision = precision_score(y_testt, y_pred_rf)\n",
    "rf_recall = recall_score(y_testt, y_pred_rf)\n",
    "rf_f1 = f1_score(y_testt, y_pred_rf)\n",
    "rf_confusion = confusion_matrix(y_testt, y_pred_rf)\n",
    "print(\"Random Forest - Accuracy:\", rf_accuracy)\n",
    "print(\"Random Forest - Precision:\", rf_precision)\n",
    "print(\"Random Forest - Recall:\", rf_recall)\n",
    "print(\"Random Forest - F1 Score:\", rf_f1)\n",
    "print(\"Random Forest - Confusion Matrix:\\n\", rf_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a743b245-a13b-4a66-a632-6d7e6be669b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes - Accuracy: 0.8488333333333333\n",
      "Naïve Bayes - Precision: 0.8416306594025925\n",
      "Naïve Bayes - Recall: 0.9859154929577465\n",
      "Naïve Bayes - F1 Score: 0.9080774298165603\n",
      "Naïve Bayes - Confusion Matrix:\n",
      " [[ 613  843]\n",
      " [  64 4480]]\n"
     ]
    }
   ],
   "source": [
    "nb_precision = precision_score(y_testt, y_pred_nb)\n",
    "nb_recall = recall_score(y_testt, y_pred_nb)\n",
    "nb_f1 = f1_score(y_testt, y_pred_nb)\n",
    "nb_confusion = confusion_matrix(y_testt, y_pred_nb)\n",
    "print(\"Naïve Bayes - Accuracy:\", nb_accuracy)\n",
    "print(\"Naïve Bayes - Precision:\", nb_precision)\n",
    "print(\"Naïve Bayes - Recall:\", nb_recall)\n",
    "print(\"Naïve Bayes - F1 Score:\", nb_f1)\n",
    "print(\"Naïve Bayes - Confusion Matrix:\\n\", nb_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c007a88f-49f1-4e66-a777-7d87c96c26d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step\n",
      "LSTM - Accuracy: 0.7573333382606506\n",
      "LSTM - Precision: 0.7573333333333333\n",
      "LSTM - Recall: 1.0\n",
      "LSTM - F1 Score: 0.8619119878603946\n",
      "LSTM - Confusion Matrix:\n",
      " [[   0 1456]\n",
      " [   0 4544]]\n"
     ]
    }
   ],
   "source": [
    "lstm_accuracy = lstm_eval[1]\n",
    "lstm_loss = lstm_eval[0]\n",
    "y_pred_lstm = (model.predict(X_test) > 0.5).astype(int)\n",
    "lstm_precision = precision_score(y_test, y_pred_lstm)\n",
    "lstm_recall = recall_score(y_test, y_pred_lstm)\n",
    "lstm_f1 = f1_score(y_test, y_pred_lstm)\n",
    "lstm_confusion = confusion_matrix(y_test, y_pred_lstm)\n",
    "print(\"LSTM - Accuracy:\", lstm_accuracy)\n",
    "print(\"LSTM - Precision:\", lstm_precision)\n",
    "print(\"LSTM - Recall:\", lstm_recall)\n",
    "print(\"LSTM - F1 Score:\", lstm_f1)\n",
    "print(\"LSTM - Confusion Matrix:\\n\", lstm_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadcca61",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning\n",
    "- Perform hyperparameter tuning for selected models using:\n",
    "  - Grid Search\n",
    "  - Random Search\n",
    "- Explain the chosen hyperparameters and justify their selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6da33b58-423f-434f-b9ce-14dba117e6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Logistic Regression: {'C': 10, 'solver': 'liblinear'}\n",
      "Best Accuracy for Logistic Regression: 0.8875714285714287\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "log_reg_params = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  \n",
    "    'solver': ['liblinear', 'lbfgs']  \n",
    "}\n",
    "#Grid search\n",
    "grid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params, cv=5, scoring='accuracy')\n",
    "grid_log_reg.fit(x_train, y_trainn)\n",
    "print(\"Best Parameters for Logistic Regression:\", grid_log_reg.best_params_)\n",
    "print(\"Best Accuracy for Logistic Regression:\", grid_log_reg.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46012a70-460b-42af-a958-a31aff2ed249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "svm_params = {\n",
    "     'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']  \n",
    "}\n",
    "grid_svm = GridSearchCV(SVC(), svm_params, cv=5, scoring='accuracy')\n",
    "grid_svm.fit(x_train, y_trainn)\n",
    "print(\"Best Parameters for SVM:\", grid_svm.best_params_)\n",
    "print(\"Best Accuracy for SVM:\", grid_svm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e40cb3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Naive Bayes: {'alpha': 0.1}\n",
      "Best Accuracy for Naive Bayes: 0.8675714285714285\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "nb_params = {\n",
    "    'alpha': [0.1, 0.5, 1, 2]  \n",
    "}\n",
    "grid_nb = GridSearchCV(MultinomialNB(), nb_params, cv=5, scoring='accuracy')\n",
    "grid_nb.fit(x_train, y_trainn)\n",
    "print(\"Best Parameters for Naive Bayes:\", grid_nb.best_params_)\n",
    "print(\"Best Accuracy for Naive Bayes:\", grid_nb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff757fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "random_rf = RandomizedSearchCV(RandomForestClassifier(), rf_params, n_iter=10, cv=5, scoring='accuracy', random_state=42, n_jobs=-1)\n",
    "random_rf.fit(x_train, y_trainn)\n",
    "print(\"Best Parameters for Random Forest (Randomized Search):\", random_rf.best_params_)\n",
    "print(\"Best Accuracy for Random Forest (Randomized Search):\", random_rf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd94d72c-88fc-40f1-9da1-477dc2b6d6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de5ed1-8b34-4fda-9d73-2cb4b4c29495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81af8811-3fd9-47bc-9469-7777646fe587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c2abbd-ef65-4b2f-87ac-6d87051a4e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c35708-1cb9-4e7e-86ab-bdc2d2e05529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa9a658c",
   "metadata": {},
   "source": [
    "## 7. Comparative Analysis\n",
    "- Compare the performance of all models based on evaluation metrics.\n",
    "- Identify strengths and weaknesses of each model (e.g., speed, accuracy, interpretability).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca98074-5a74-434b-a653-28f96a658dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885e004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43a9c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e59b624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf254f52",
   "metadata": {},
   "source": [
    "## 8. Conclusion & Comments\n",
    "- Summarize the findings of the project.\n",
    "- Provide insights into the challenges faced during data preprocessing, model training, and evaluation.\n",
    "- Highlight key lessons learned.\n",
    "- Add clear and concise comments to the code for each step of the project.\n",
    "- Highlight key results, visualizations, and model comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464bee8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085e0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecea79f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
